<!DOCTYPE html>
<!--
  Author: Anjan Roy<hello@itzmeanjan.in>
-->
<html>

<head>
    <title>
        TurboSHAKE: SHAKE on Steroids
    </title>
    <meta prefix="og: http://ogp.me/ns#" property="og:type" content="website">
    <meta prefix="og: http://ogp.me/ns#" property="og:title" content="TurboSHAKE: SHAKE on Steroids">
    <meta prefix="og: http://ogp.me/ns#" property="og:description" content="TurboSHAKE offers much faster hashing than SHAKE, based on round reduced keccak-p[1600, 12] permutation. It is defined in RFC 9861.">
    <meta prefix="og: http://ogp.me/ns#" property="og:url" content="https://itzmeanjan.in">
    <meta prefix="og: http://ogp.me/ns#" property="og:image" content="https://itzmeanjan.in/images/myImage.jpg">
    <meta prefix="og: http://ogp.me/ns#" property="og:image:secure_url" content="https://itzmeanjan.in/images/myImage.jpg">
    <meta prefix="og: http://ogp.me/ns#" property="og:image:width" content="950">
    <meta prefix="og: http://ogp.me/ns#" property="og:image:height" content="735">
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://itzmeanjan.in/">
    <meta property="twitter:title" content="TurboSHAKE: SHAKE on Steroids">
    <meta property="twitter:description" content="TurboSHAKE offers much faster hashing than SHAKE, based on round reduced keccak-p[1600, 12] permutation. It is defined in RFC 9861.">
    <meta property="twitter:image" content="https://itzmeanjan.in/images/myImage.jpg">
    <meta property="twitter:site" content="@meanjanroy">
    <meta name="description" content="TurboSHAKE offers much faster hashing than SHAKE, based on round reduced keccak-p[1600, 12] permutation. It is defined in RFC 9861.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="Anjan Roy">
    <meta name="keywords" content="---">
    <meta name="theme-color" content="darkslategrey">
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
    <link rel="stylesheet" type="text/css" href="../styles/index.css">
    <script src="../styles/code.js"></script>
</head>

<body>
    <div id="parentDiv">
        <div id="navBar">
            <nav>
                <a class="navLink" href="/"><big>H</big>ome</a> |
                <a class="navLink" href="https://github.com/itzmeanjan" target="_blank"><big>P</big>rojects</a> |
                <a class="navLink" href="https://gist.github.com/itzmeanjan" target="_blank"><big>G</big>ists</a> |
                <a class="navLink" href="/pages/blog.html"><big>B</big>log</a> |
                <a class="navLink" href="/pages/talks.html"><big>T</big>alks</a> |
                <a class="navLink" href="/pages/contact.html"><big>C</big>ontact</a>
            </nav>
        </div>
        <div class="childDiv">
            <article>
                <h1 class="blogHeader">
                    TurboSHAKE: SHAKE on Steroids
                </h1>
                <h3>Created : November 13, 2025</h3>
            </article>
        </div>
        <div class="childDiv">
            <article>
                <p class="blogText">
                    NIST's SHA3 standard <a class="blogLink" href="https://doi.org/10.6028/NIST.FIPS.202" target="_blank">FIPS 202</a>, which defines four hash functions and two eXtendable Output Functions (XOFs),
                    based on 24-rounds keccak-p[1600] permutation, offers an excellent security margin. Keccak permutation and sponge mode of operation has been extensively studied for more than a decade now.
                    And the cryptanalysis community largely agrees that using 24-rounds keccak permutation is an overkill. SHA3 is known for being relatively slow in software, though it is performant in hardware.
                    And 24-rounds keccak permutation eats a large pie from SHA3's software performance. To make keccak permutation based hashing faster in software, keccak team has written up <a class="blogLink" href="https://www.rfc-editor.org/info/rfc9861" target="_blank">RFC 9861</a>,
                    which proposes two families of XOFs - TurboSHAKE and KangarooTwelve. TurboSHAKE is simply SHAKE (from FIPS 202), just powered by 12-rounds keccak-p[1600] permutation. While KangarooTwelve builds a tree hashing
                    mode on top of TurboSHAKE for much faster SIMD and/or multi-threaded parallel hashing. KangarooTwelve shines on modern multi-core, multi-CPU machines, where each CPU features several SIMD registers, offering GB/s of throughput.
                    In this writing, we will just focus on TurboSHAKE - which is a good fit for replacing SHAKE XOF.
                </p>
                <p class="blogText">
                    In SHA3 standard FIPS 202, two XOFs are defined - SHAKE128 and SHAKE256. SHAKE behaves like a flexible hash function. Usually a cryptographic hash function produces a fixed length message digest. For example,
                    SHA3-256, is a hash function defined in FIPS 202, which produces a 32-bytes message digest for any arbitrary length input it consumes. While SHAKE128, can absorb an arbitrary length message, just like a hash function, though on the other side,
                    it can produce an arbitrary length output i.e. message digest. An extendable output function (XOF) behaves like a sponge - it can absorb arbitrary long message, then it can be squeezed to produce as long output is required.
                    The flexibility that SHAKE offers, makes it a really good fit for producing a long pseudo-random stream of bytes. All the post-quantum cryptographic schemes, be that key encapsulation mechanism (KEM) or digital signature algorithm (DSA),
                    use a XOF to expand a fixed seed to a matrix or vector. A XOF can be seeded with entropy sampled from non-deterministic sources to build a cryptographically secure psuedo-random number generator (CSPRNG), coupled with occasional ratcheting.
                    A XOF can be used as the basis for key derivation function, so that keying material can be extended to produce longer key material, to be used with other protocols.
                    But SHAKE is slow in software. Hence we have TurboSHAKE - which simply doubles throughput of keccak permutation-based extendable-output hashing, by halving the number of keccak permutation rounds to 12.
                </p>
                <p class="blogText">
                    In rest of the writing, we will focus on <span class="highlight">sha3</span> - a fully constexpr, portable, C++ header-only library implementation of SHA3 suite of hash functions.
                    The library is available @ <a class="blogLink" href="https://github.com/itzmeanjan/sha3" target="_blank">https://github.com/itzmeanjan/sha3</a>. Being a header-only library, it's very easy to
                    get started with. XKCP is the state-of-the-art C library implementation of everything keccak permutation based. It's available @ <a class="blogLink" href="https://github.com/XKCP/XKCP" target="_blank">https://github.com/XKCP/XKCP</a>.
                    On the other hand, <span class="highlight">sha3</span> is not optimized for any specific platform, it is portable and uses modern C++ language and standard library features to offer an easy-to-drive feel.
                    One competitive advantage <span class="highlight">sha3</span> has over XKCP is, it's fully constexpr - meaning, given the input message is known at program compile-time, it should be possible to compute message digest (MD) using any of
                    the SHA3 algorithms, in program compile-time itself.
                </p>
                <div class="microlight">
#include "sha3/sha3_256.hpp"
#include &lt;array&gt;
#include &lt;cstdint&gt;
#include &lt;cstdlib&gt;
#include &lt;string_view&gt;

template&lt;size_t L&gt;
constexpr std::array&lt;uint8_t, L&gt;
string_to_bytes(std::string_view sv)
{
  std::array&lt;uint8_t, L&gt; arr{};

  for (size_t i = 0; i &lt; sv.size(); i++) {
    arr[i] = static_cast&lt;uint8_t&gt;(sv[i]);
  }

  return arr;
}

constexpr std::string_view MSG = "keccak permutation rocks!";
constexpr auto MSG_bytes = string_to_bytes&lt;MSG.size()&gt;(MSG);
constexpr auto MD = sha3_256::sha3_256_t::hash(MSG_bytes);

int
main()
{
  // 4edc60a9ffe739ce44252716483a529e8a859a5a75cbf69d494037e914bac16b
  constexpr std::array&lt;uint8_t, sha3_256::DIGEST_LEN&gt; expected_md = { 78,  220, 96,  169, 255, 231, 57,  206, 68, 37, 39, 22,  72, 58,  82,  158,
                                                                      138, 133, 154, 90, 117, 203, 246, 157, 73, 64, 55, 233, 20, 186, 193, 107 };
  static_assert(MD == expected_md, "Must compute SHA3-256 message digest in program compile-time!");

  return EXIT_SUCCESS;
}
                </div>
                <p class="blogText">
                    In above code snippet, notice the input message to be hashed is known at program compile-time <span class="highlight">"keccak permutation rocks!"</span>.
                    We can use <span class="highlight">sha3</span> header-only C++ library to compute message digest of this string at program compile-time and embed the MD
                    as a constant in program. Each of the SHA3 functions are implemented as <span class="highlight">constexpr</span> function. It's a modern C++ language feature.
                    It allows some functions to be executed by the compiler, to pre-compute the result or sub-result, given that the input is known at compile-time.
                    It is a really useful feature because one can run a <span class="highlight">static_assert(...)</span> against the compiler computed value to enforce free correctness check.
                    Just to show that the compile-time computed SHA3-256 digest, in above code snippet, is correct, we present following Python REPL output.
                </p>
                <div class="microlight">
&gt; python
Python 3.13.7 (main, Aug 20 2025, 22:17:40) [GCC 15.2.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import hashlib
>>> hashlib.sha3_256(b'keccak permutation rocks!').digest().hex()
'4edc60a9ffe739ce44252716483a529e8a859a5a75cbf69d494037e914bac16b'
>>>
                </div>
                <p class="blogText">
                    Let's jump back to TurboSHAKE. In a recent pull request <a class="blogLink" href="https://github.com/itzmeanjan/sha3/pull/32" target="_blank">https://github.com/itzmeanjan/sha3/pull/32</a>,
                    we have added support for hashing with TurboSHAKE in <span class="highlight">sha3</span> - our small footprint, portable, C++20 header-only library implementation of SHA3 suite.
                    And more importantly, all TurboSHAKE functions are also <span class="highlight">constexpr</span> - meaning, you can compile-time evaluate arbitrary long TurboSHAKE128 or TurboSHAKE256 output,
                    for any compile-time known message. Following code snippet demonstrates how to use TurboSHAKE128 API.
                </p>
                <div class="microlight">
// File name: turboshake128.cpp

#include &lt;iostream&gt;
#include &lt;numeric&gt;
#include &lt;vector&gt;
#include &lt;cstdint&gt;
#include &lt;iomanip&gt;
#include &lt;span&gt;
#include &lt;sstream&gt;

#include "sha3/turboshake128.hpp"

// Given a bytearray of length N, this function converts it to hex string of length N/2 | N >= 0.
static inline std::string
to_hex(std::span&lt;const uint8_t&gt; bytes)
{
  std::stringstream ss;
  ss << std::hex;

  for (size_t i = 0; i < bytes.size(); i++) {
    ss << std::setw(2) << std::setfill('0') << static_cast<uint32_t>(bytes[i]);
  }

  return ss.str();
}

// Compile it using
//
// g++ -std=c++20 -Wall -O3 -march=native -I include turboshake128.cpp
int
main()
{
  constexpr size_t msg_len = 32;
  constexpr size_t out_len = 40;

  std::vector&lt;uint8_t&gt; msg(msg_len, 0);
  std::iota(msg.begin(), msg.end(), 0);

  std::vector&lt;uint8_t&gt; out(out_len, 0);
  auto out_span = std::span(out);

  // Create TurboSHAKE128 hasher.
  turboshake128::turboshake128_t hasher;

  // Absorb message bytes into sponge state.
  //
  // Instead of absorbing the whole message in a single shot, one could have
  // absorbed it by invoking `absorb()` as many times required, before finalizing it.
  hasher.absorb(msg);

  // Finalize sponge state
  hasher.finalize();

  // Squeeze total `out_len` -bytes out of sponge, a single byte at a time.
  // One can request arbitrary many bytes of output, by calling `squeeze` arbitrary
  // many times, after it has been finalized.
  //
  // Or we could have just squeezed all `out_len` -bytes in a single go.
  for (size_t i = 0; i < out_len; i++) {
    hasher.squeeze(out_span.subspan(i, 1));
  }

  std::cout << "TurboSHAKE128" << std::endl << std::endl;
  std::cout << "Message  : " << to_hex(msg) << "\n";
  std::cout << "Output   : " << to_hex(out) << "\n";

  return EXIT_SUCCESS;
}
                </div>
                <p class="blogText">
                    Time to run a benchmark comparison, to see how fast TurboSHAKE128 is compared to SHAKE128, on a x86_64 machine of Intel Alderlake architecture,
                    running Linux kernel <span class="highlight">6.17.0-6-generic</span>. We compiled the benchmark executable with GCC 15.2.0, while turning on full
                    optimization by passing <span class="highlight">-O3 -march=native -flto</span>. Following benchmark comparison clearly shows, TurboSHAKE128 has
                    ~45% lesser latency compared to SHAKE128, for all input sizes. This matches our expectation. Both SHAKE128 and TurboSHAKE128 have exact same sponge
                    parameters i.e. same rate and capacity. Just the difference is in which permutation is used. In TurboSHAKE128, we are using faster 12-rounds keccak-p[1600, 12]
                    permutation, compared to full round keccak-p[1600, 24] permutation in SHAKE128.
                </p>
                <img class="imgCenter" src="../images/turboshake-shake-on-steroids-benchcmp-shake128-vs-turboshake128-on-x86_64.png">
                <p class="blogText">
                    On the same machine, with similar compilation configuration, we see 12-rounds keccak-p[1600, 12] permutation taking ~93ns, compared to
                    ~181ns for 24-rounds keccak-p[1600, 24] permutation. That's a ~48% drop in latency for keccak permutation. And it's powering our TurboSHAKE performance gain.
                </p>
                <img class="imgCenter" src="../images/turboshake-shake-on-steroids-keccak-permutation-perf-on-x86_64.png">
                <p class="blogText">
                    TurboSHAKE's choice of using 12-rounds keccak permutation for faster hashing still provides us with sufficient cryptographic security margin.
                    And given the performance gain that comes from switching to TurboSHAKE from SHAKE is a strong indicator to adopt TurboSHAKE and enjoy the cake.
                    <br>
                    <br>
                    Before finishing off, we want to run a performance comparison between TurboSHAKE implementation in <span class="highlight">sha3</span> vs.
                    XKCP's optimized TurboSHAKE implementation in C. In the following section, we will refer to <span class="highlight">sha3</span>'s C++ header-only
                    library implementation of TurboSHAKE as <span class="highlight"><b>portable-turboshake</b></span> - for sake of brevity. We use <span class="highlight"><i>google-benchmark</i></span>
                    library as our choice of benchmark harness. Google-benchmark is a feature-rich C++ library for micro-benchmarking, available @ <a class="blogLink" href="https://github.com/google/benchmark/tree/v1.9.4" target="_blank">https://github.com/google/benchmark/tree/v1.9.4</a>.
                    When running the benchmark comparison, we pinned <span class="highlight"><b>portable-turboshake</b></span> to git commit <span class="highlight"><i>2fa340596daf72e116cb0124ca55f068ce857bb5</i></span>.
                    While XKCP was pinned to git commit <span class="highlight"><i>e7a08f7baa3d43d64f5c21e641cb18fe292f2b75</i></span>. For easy benchmark comparison, we use compare.py tool from
                    <span class="highlight">google-benchmark</span> with JSON dump from benchmark execution. More documentation on this really useful tool @ <a class="blogLink" href="https://github.com/google/benchmark/blob/v1.9.4/docs/tools.md" target="_blank">https://github.com/google/benchmark/blob/v1.9.4/docs/tools.md</a>.
                    <br>
                    <br>
                    Without any further adieu, let's benchmark compare on a x86_64 desktop machine, running Linux kernel <span class="highlight">6.17.0-6-generic</span>. We will consider <span class="highlight"><b>xkcp-turboshake</b></span>
                    as the baseline. We hash variable sized messages from 32B to 1GB, separated by a multiplicative factor of 32. We fix the squeezed output byte length to 64. While hashing this wide spectrum of input, we notice
                    <span class="highlight"><b>portable-turboshake</b></span> consistently takes ~10-15% more time.
                </p>
                <img class="imgCenter" src="../images/turboshake-shake-on-steroids-benchcmp-turboshake128-portable-vs-xkcp-on-x86_64.png">
                <p class="blogText">
                    This behaviour of <span class="highlight"><b>portable-turboshake</b></span> being 10-15% slower compared to the state-of-the-art <span class="highlight"><b>xkcp-turboshake</b></span>
                    is also consistent in case of TurboSHAKE256.
                </p>
                <img class="imgCenter" src="../images/turboshake-shake-on-steroids-benchcmp-turboshake256-portable-vs-xkcp-on-x86_64.png">
                <p class="blogText">
                    For aarch64, we choose to use server-grade CPU on AWS EC2 <span class="highlight"><i>c8g.large</i></span>, featuring Graviton4 CPU, running Linux kernel <span class="highlight">6.14.0-1015-aws</span>.
                    The benchmark executable is compiled with GCC 13.3.0, while turning on all optimizations, by passing <span class="highlight">-O3 -march=native -flto</span>.
                    We run the performance comparison using <span class="highlight"><b>xkcp-turboshake</b></span> as baseline, while <span class="highlight"><b>portable-turboshake</b></span> is the contender.
                    Similar trend is clearly noticable, in following screen-captures, on aarch64 target. Both TurboSHAKE128 and TurboSHAKE256 from <span class="highlight"><b>portable-turboshake</b></span>
                    is taking ~8-16% more time compared to the baseline.
                </p>
                <img class="imgCenter" src="../images/turboshake-shake-on-steroids-benchcmp-turboshake128-portable-vs-xkcp-on-aarch64.png">
                <img class="imgCenter" src="../images/turboshake-shake-on-steroids-benchcmp-turboshake256-portable-vs-xkcp-on-aarch64.png">
                <p class="blogText">
                    We conclude that switching to TurboSHAKE for faster extendable output hashing is worth it. Enjoy almost double the throughput of SHAKE XOF.
                    While staying well within the security margin of very much publicly scrutinized keccak-p[1600] permutation and sponge mode of operation.
                    This is a clear indication that we should adopt TurboSHAKE more. To choose which library to use for fast hashing with TurboSHAKE, we can't recommend
                    XKCP enough. If performance for a wide range of targets is what you seek, XKCP is the best choice for anything keccak permutation based. It's maintained
                    by the keccak team itself. But if you are looking for a low footprint, portable, header-only, C++ library which makes use of modern C++ features such that <span class="highlight">constexpr</span> i.e. compile-time evaluable hash functions,
                    <span class="highlight">concepts</span> i.e. compile-time constraint enforcement using keccak sponge parameters and <span class="highlight">std::span</span> instead of traditional raw pointer + size-based interface, you are welcome to look into
                    <span class="highlight">sha3</span> @ <a class="blogLink" href="https://github.com/itzmeanjan/sha3" target="_blank">https://github.com/itzmeanjan/sha3</a>.
                    It's only 1096 lines of code (LOC), implementing full NIST SHA3 standard FIPS 202, with two additional XOFs from RFC 9861 i.e. TurboSHAKE128 and TurboSHAKE256.
                    Now that we have TurboSHAKE ready to use, it's good time to experiment - replace SHAKE with TurboSHAKE in NIST post-quantum cryptography standards. We explored a similar path with BLAKE3
                    and saw a performance boost of roughly 20% in ML-KEM and ML-DSA, using BLAKE3 for faster hashing instead of SHA3. It will be nice to see how close to that we can reach with TurboSHAKE.
                    Because sticking to keccak-p[1600] permutation + sponge mode of operation for faster hashing, is no doubt more reassuring than using something completely different.
                </p>
            </article>
        </div>
    </div>
    <div id="footerDiv">
        <footer>
            <p id="footerText">
                &copy <a href="https://github.com/itzmeanjan/itzmeanjan.github.io" id="footerLink"
                    target="_blank"><big>A</big>njan Roy</a> ( <big>M</big>IT Licensed )
            </p>
        </footer>
    </div>
</body>

</html>
