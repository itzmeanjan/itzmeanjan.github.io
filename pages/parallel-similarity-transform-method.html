<!DOCTYPE html>
<!--
  Author: Anjan Roy<hello@itzmeanjan.in>
-->
<html>

<head>
    <title>
        Finding Maximum Eigen Value using Parallel Similarity Transform Method
    </title>
    <meta prefix="og: http://ogp.me/ns#" property="og:type" content="website">
    <meta prefix="og: http://ogp.me/ns#" property="og:title" content="Finding Maximum Eigen Value using Parallel Similarity Transform Method">
    <meta prefix="og: http://ogp.me/ns#" property="og:description" content="In-depth analysis of both sequential and parallel implementations of Similarity Transform Method, used for quickly finding maximum eigen value ( with eigen vector ) of positive square matrix">
    <meta prefix="og: http://ogp.me/ns#" property="og:url" content="https://itzmeanjan.in">
    <meta prefix="og: http://ogp.me/ns#" property="og:image" content="https://itzmeanjan.in/images/myImage.jpg">
    <meta prefix="og: http://ogp.me/ns#" property="og:image:secure_url"
        content="https://itzmeanjan.in/images/myImage.jpg">
    <meta prefix="og: http://ogp.me/ns#" property="og:image:width" content="950">
    <meta prefix="og: http://ogp.me/ns#" property="og:image:height" content="735">
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://itzmeanjan.in/">
    <meta property="twitter:title" content="Finding Maximum Eigen Value using Parallel Similarity Transform Method">
    <meta property="twitter:description" content="In-depth analysis of both sequential and parallel implementations of Similarity Transform Method, used for quickly finding maximum eigen value ( with eigen vector ) of positive square matrix">
    <meta property="twitter:image" content="https://itzmeanjan.in/images/myImage.jpg">
    <meta property="twitter:site" content="@meanjanry">
    <meta name="description" content="In-depth analysis of both sequential and parallel implementations of Similarity Transform Method, used for quickly finding maximum eigen value ( with eigen vector ) of positive square matrix">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="Anjan Roy">
    <meta name="keywords"
        content="dpc++, dpcpp, sycl, oneapi, gpgpu, fpga, accelerator, similarity, transform, method, maximum, eigen value, eigen vector, positive, square, matrix, simt, cpp">
    <meta name="theme-color" content="darkslategrey">
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
    <link rel="stylesheet" type="text/css" href="../styles/index.css">
    <script src="../styles/code.js"></script>
</head>

<body>
    <div id="parentDiv">
        <div id="navBar">
            <nav>
                <a class="navLink" href="/"><big>H</big>ome</a> |
                <a class="navLink" href="https://github.com/itzmeanjan" target="_blank"><big>P</big>rojects</a> |
                <a class="navLink" href="https://gist.github.com/itzmeanjan" target="_blank"><big>G</big>ists</a> |
                <a class="navLink" href="/pages/blog.html"><big>B</big>log</a> |
                <a class="navLink" href="/pages/talks.html"><big>T</big>alks</a> |
                <a class="navLink" href="/pages/contact.html"><big>C</big>ontact</a>
            </nav>
        </div>
        <div class="childDiv">
            <article>
                <h1 class="blogHeader">
                    Finding Maximum Eigen Value using Parallel Similarity Transform Method
                </h1>
                <h3>Created : November 08, 2021</h3>
            </article>
        </div>
        <div class="childDiv">
            <article>
                <p class="blogText">
                    Last week I started working on implementing Similarity Transform Method, which is an iterative method
                    for quickly finding maximum eigen value along with respective eigen vector for a positive square matrix. Today
                    I plan to go through this method step-by-step, while first developing its sequential implementation and finally
                    moving to parallel implementation, written targeting heterogeneous platforms i.e. CPU, GPU, FPGA etc. using SYCL DPC++.
                    Finally I'd like to do some performance comparison between sequential and parallel implementations, both written by me.
                </p>
                <p class="blogText">
                    As Similarity Transform works with positive square matrices, I'd like to fix one matrix, which I'll work on. Let me call it A<sub>N x N</sub>, where N = 3.
                </p>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-0.png">
                <p class="blogText">
                    I start with finding sum of elements across each row of A<sub>N x N</sub>. I can write  code snippet for computing that.
                </p>
                <div class="microlight">
    def sum_across_rows(mat):
        n = mat.shape[1]
        v = np.array([np.sum(mat[i]) for i in range(n)])
        return v
                </div>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-1.png">
                <p class="blogText">
                    Notice, I mark maximum row sum as we've to use it for computing eigen vector ( iteratively ) in next step.
                    I initialise iteratively computed eigen vector with <span class="highlight">[1; N]</span> and during each iteration
                    following function is used for updating eigen vector, while reaching closer to desired values.
                </p>
                <div class="microlight">
    eigen_vec = np.ones(3) // == [1] * 3
    sum_across_rows = [6, 9, 12]
    
    def compute_eigen_vector(eigen_vec, sum_across_rows):
        max_row = np.max(sum_across_rows) // == 12
        return np.array([j * (sum_across_rows[i]/max_row) for i, j in enumerate(eigen_vec)])
                </div>
                <p class="blogText">
                    Now I'd like to present next step where I check whether we've converged to maximum eigen value or not. It's as simple
                    as checking whether all consecutive absolute differences between cells of <i>sum_across_rows</i> vector are below of preset
                    epsilon value, which I consider to be error induced during floating point arithmetics. If all consecutive differences are below
                    say, <b>EPS = 1e-5</b>, it denotes it's good time to stop this iterative method, as we've converged to maximum eigen value
                    of given matrix. I can take very first element of <i>sum_across_rows</i> vector ( in final round ) and consider it to be
                    maximum eigen value, we're looking for.
                    <br>
                    <br>
                    I write convergence criteria checker function as below. In very first iteration, we're far from convergence, as our row sum vector looks like
                    <span class="highlight">[6, 9, 12]</span> --- so answer is negative and we'll continue to next iteration.
                </p>
                <div class="microlight">
    EPS = 1e-5

    def converged(sum_vec) -> bool:
        return all(map(lambda e: e < EPS, [abs(sum_vec[i] - sum_vec[i-1]) for i in range(1, len(sum_vec))]))
                </div>
                <p class="blogText">
                    Before I prepare A<sub>N x N</sub> for next iteration, this is how current eigen vector looks like.
                </p>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-2.png">
                <p class="blogText">
                    In final step, I take <i>sum_across_rows</i> vector and prepare diagonal matrix D<sub>N x N</sub> and D<sub>N x N</sub><sup>-1</sup>, 
                    using those I compute A<sup>'</sup><sub>N x N</sub> for next iteration. I programmatically express that logic .
                </p>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-3.png">
                <div class="microlight">
    def compute_next(mat, sum_vec):
        sigma = np.diag(sum_vec)
        sigma_inv = np.diag(1/ sum_vec)
        return np.matmul(np.matmul(sigma_inv, mat), sigma)
                </div>
                <p class="blogText">
                    With completion of this step, I've following matrix, which is to be worked on during next iteration.
                </p>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-4.png">
                <p class="blogText">
                    In second iteration, I already find <i>sum_across_rows</i> vector having lesser consecutive absolute differences --- tending to converge.
                </p>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-5.png">
                <p class="blogText">
                    After going through each of these steps, during 5<sup>th</sup> iteration, convergence criteria is fully satisfied, resulting into following eigen value and corresponding eigen vector.
                </p>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-6.png">
                <p class="blogText">
                    Just to check that these are correct, I assert following, while considering some floating point arithmetics error will
                    probably be present.
                </p>
                <div class="microlight">
    Av = 位v // must satisfy !

    A = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])
    v = np.array([0.49835378, 0.72407576, 0.94979774])
    位 = 9.623376623376622

    // set `atol` to EPS
    // during demonstration EPS = 1e-3
    >>> assert np.allclose(np.dot(a, vec), np.dot(v, vec), atol=1e-3)
    >>> print(f'Av = {np.dot(A, v)}\n位v = {np.dot(位, v)}')
    
    Av = [4.79589852 6.9681258  9.14035308]
    位v = [4.79584612 6.96805374 9.14026137]
                </div>
                <p class="blogText">
                    I keep full sequential implementation of Similarity Transform Method <a class="blogLink" target="_blank" href="https://github.com/itzmeanjan/eigen_value/blob/964695e244f122cca8bed73b8f68364e9ee6a154/main.py">here</a> for future reference.
                    Now it's good time to talk about parallel implementation of this method. First step i.e. summing N-many elements across N-many rows
                    is easily parallelizable. I'm currently making use of atomic instructions for spawning <span class="highlight">N x N</span>
                    work-items, each reading value from cell A<sub>i, i</sub> and atomically summing up values along each row. In second step, I find maximum
                    value from just computed N-element vector i.e. <i>sum_across_rows</i>. Here also I make use of atomic instructions for parallelly
                    computing maximum element of vector. Third step consists of updating eigen vector with <i>sum_across_rows</i> of this iteration, which is
                    also a good candidate of parallel computing. Each of N-many work-items updating a single cell of eigen vector. Finally, it requires me to
                    perform two matrix multiplications in last step, but given that two of these three operands are diagonal matrices and one is inverse of another, I can compute matrix for next round using  trick.
                    This trick lends itself to heavy parallelism and each cell of A<sub> N x N</sub> matrix can be computed independently using
                    <span class="highlight">N x N</span> work-items.
                </p>
                <img class="imgCenterUpdt" src="../images/parallel-similarity-transform-method-7.png">
                <p class="blogText">
                    I've also parallel implementation for checking whether current round has reached convergence criteria or not, using atomic
                    instructions. Empowered with these, I'm ready to run both sequential and data parallel implementation for performance comparison.
                    Starting with sequential implementation I wrote in Python. This is a single threaded implementation using <i>numpy</i> for doing
                    matrix algebra. Note performance when N = 1024 ( read last row ).
                </p>
                <div class="microlight">
    // check https://github.com/itzmeanjan/eigen_value/tree/964695e#sequential-reference-implementation
    $ python3 main.py

    Sequential Similarity Transform, for finding maximum eigen value ( with vector )

    32   x   32               1.27 ms                      5 round(s)
    64   x   64               2.44 ms                      5 round(s)
    128  x  128               9.67 ms                      5 round(s)
    256  x  256              20.58 ms                      4 round(s)
    512  x  512              74.24 ms                      4 round(s)
    1024 x 1024             335.77 ms                      4 round(s)                    
                </div>
                <p class="blogText">
                    Data parallel implementation powered by <b>U</b>nified <b>S</b>hared <b>M</b>emory and atomics doesn't perform very well, compared
                    to previous one. Note, for both data parallel and sequential implementations, I'm using randomly generated positive square matrices
                    with each cell taking value from [0, 1).
                </p>
                <div class="microlight">
    // check https://github.com/itzmeanjan/eigen_value/tree/964695e#benchmark
    $ make && ./run
    running on Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz

    Parallel Algorithm using Similarity Transform for finding max eigen value (with vector)
    
    32   x   32                              4 ms
    64   x   64                            200 ms
    128  x  128                            203 ms
    256  x  256                            442 ms
    512  x  512                            755 ms
    1024 x 1024                           1860 ms
    
    --- --- --- --- --- --- --- --- --- --- --- ---
    
    $ make && ./run
    running on Intel(R) Xeon(R) Gold 6128 CPU @ 3.40GHz

    Parallel Algorithm using Similarity Transform for finding max eigen value (with vector)
    
    32   x   32                            150 ms
    64   x   64                            117 ms
    128  x  128                            159 ms
    256  x  256                            182 ms
    512  x  512                            270 ms
    1024 x 1024                            440 ms
                </div>
                <p class="blogText">
                    I'd like to note few points, regarding why data parallel implementation doesn't do better than sequential one.
                </p>
                <ol>
                    <li>I'm making use of atomic instructions a lot, which limits scalability by underlying device's atomic instruction execution ability</li>
                    <li>I will consider using blocked reading from global memory using vectors of width 2/ 4/ 8, which will promote usage of coalesced memory access</li>
                    <li>While computing matrix for next iteration, I'm accessing same cells of <i>sum_across_rows</i> vector multiple times, which results into duplicate, improperly strided global memory reads</li>
                    <li>Speaking of previous note, I'll consider using cheaper & faster local scratch pad memory in better way, so that I don't end up generating many duplicate global memory accesses</li>
                </ol>
                <p class="blogText">
                    Keeping aforementioned points in mind, I end today's discussion. I keep full implementation of both sequential and parallel similarity transform methods
                    in this <a class="blogLink" target="_blank" href="https://github.com/itzmeanjan/eigen_value/tree/964695e">repository</a>. In coming days, I'll try to
                    improve data parallel implementation, while also sharing my findings.
                    <br>
                    <br>
                    Have a great time !
                </p>
            </article>
        </div>
    </div>
    <div id="footerDiv">
        <footer>
            <p id="footerText">
                &copy <a href="https://github.com/itzmeanjan/itzmeanjan.github.io" id="footerLink"
                    target="_blank"><big>A</big>njan Roy</a> ( <big>M</big>IT Licensed )
            </p>
        </footer>
    </div>
</body>

</html>
